#!/usr/bin/env python

import os, sys, re, glob, shutil, hashlib, subprocess
from optparse import OptionParser
from datetime import datetime
from PIL import Image, ExifTags

def main():
	'''
	parse command line options and take appropriate action
	'''
	import optparse
	
	# define and parse command-line options
	prog = os.path.basename(sys.argv[0])
	usage = "Usage: %s [options] action source dest" % prog
	
	parser = optparse.OptionParser(usage)
	parser.add_option("-c", "--copy",    dest="move",    action="store_true",  help="copy files to destination [default]")
	parser.add_option("-m", "--move",    dest="move",    action="store_false", help="move files to destination")
	parser.add_option("-v", "--verbose", dest="verbose", action="store_true")
	parser.add_option("-q", "--quiet",   dest="verbose", action="store_false")
	
	# sort action options
	group = optparse.OptionGroup(parser, "Sort Photos", "Usage: %s [options] sort source dest" % prog)
	group.add_option("-n", "--name",     dest="name",     help="specify a bucket name for this image source (default is the source directory name)", metavar="NAME")
	group.add_option("-p", "--preserve", dest="preserve", action="store_true",  help="keep all alternates including low-res and duplicates [default]")
	group.add_option("-d", "--discard",  dest="preserve", action="store_false", help="discard duplicates and low-res alternates.")
	parser.add_option_group(group)
	
	# restore action options
	group = optparse.OptionGroup(parser, "Restore Original Filenames", "Usage: %s [options] restore source [dest]" % prog)
	parser.add_option_group(group)
	
	# fix action options
	group = optparse.OptionGroup(parser, "Fix Photo Dates", "Usage: %s [options] fix source [dest]" % prog)
	parser.add_option_group(group)
	
	# parse our options
	parser.set_defaults(verbose=True, move=False, preserve=True)
	(options, args) = parser.parse_args()
	
	if len(args) == 0:
		parser.print_help()
		return
	elif args[0] not in ('sort','fix','restore'):
		parser.error("Invalid action provided")
	elif args[0] in ('fix','restore') and len(args) == 2:
		args.append(args[1])
	elif len(args) != 3:
		parser.error("Incorrect number of arguments")
	
	(action, src, dest) = args
	src  = src.rstrip('/\\')
	dest = dest.rstrip('/\\')
		
	# ensure source and destination both exist and are directories
	for path in (src, dest):
		if not os.path.isdir(path):
			parser.error("No such file or directory '%s'" % path)
	
	# handle sort action
	if action == 'sort':
		if not options.name:
			options.name = os.path.basename(os.path.abspath(src))
		
		name = unique_name(options.name, dest)
		if name != options.name:
			print "[WARNING] A file or directory named '%s' already exists at '%s'. Using '%s' instead." % (options.name, dest, name)
		
		sort_images(src, dest, name, options.move, options.verbose)
	
	# handle restore action
	if action == 'restore':
		restore_images(src, dest, options.move, options.verbose)
	
	# handle fix action
	if action == 'fix':
		fix_images(src, dest, options.move, options.verbose)


def sort_images(src, dest, src_bucket, move=False, verbose=True):
	'''
	sort images within src to labeled buckets within dest
	'''
	
	# generate our log closure
	logfile = dest + '/' + src_bucket + '/_sort.log.txt'
	prefix = "\nSOURCE: %s\n" % src_bucket
	log = logger(logfile, verbose, prefix)
	
	# ensure the source and destination exist
	if not os.path.isdir(src) or not os.path.isdir(dest):
		raise IOError('Source or destination directory not found')
	
	# ensure the destination bucket exists
	assert_dir(dest+'/'+src_bucket, "Unable to create needed directories within destination ('%s')" % dest)
	
	# capture all directory names within dest path, ensure src_bucket is last in the list
	buckets = filter(lambda name: os.path.isdir(dest + '/' + name), os.listdir(dest))
	buckets.remove(src_bucket)
	buckets += [src_bucket]
	
	log("Reading from '%s' (%s)...\n" % (src, src_bucket))
	log("Sorting Images...\n")
	
	# iterate through all files within src
	files = get_all_files(src)
	
	for filepath in files:
		# capture filename and extension
		filename = os.path.basename(filepath)
		extension = os.path.splitext(filename)[1].lower()
		
		# generate local file path
		relpath = re.sub('^%s/?' % src, '', filepath)
		
		# attempt to obtain file meta-data
		filemeta = get_file_metadata(filepath)
		filehash = get_file_hash(filepath)[:6:]
		
		if not filemeta:
			# file is not an image
			log('Non-Image Found: %s' % relpath)
			log('- hash: %s' % filehash)
		else:
			# file is an image
			date = filemeta['date_taken'] or filemeta['file']['mtime']
			log('Image Found: %s' % relpath)
			log('- hash: %s' % filehash)
			log('- date: %s' % date.strftime('%Y/%m/%d %H.%M.%S'))


def restore_images(src, dest, move=False, verbose=True):
	'''
	restore image filenames generated by sort_images
	'''
	
	# generate our log closure
	log = logger(dest + '/_restore.log.txt', verbose)
	
	log("Restoring Filenames...\n\n...\n")


def fix_images(src, dest, move=False, verbose=True):
	'''
	correct image date metadata
	'''
	
	# generate our log closure
	log = logger(dest + '/_fix.log.txt', verbose)
	
	log("Fixing Image Dates...\n\n...\n")


def assert_dir(dirs, message=None):
	'''
	ensures a directory exists at each path specified in dirs.
	
	raises an exception if a directory does not exist and it is unable to create one.
	'''
	if not type(dirs) == list:
		dirs = [dirs]
	for dir in dirs:
		try:
			os.makedirs(dir)
		except OSError:
			if not os.path.isdir(dir):
				if not message:
					message = "Unable to create needed directory ('%s')" % dir
				raise IOError(message)


def unique_name(name, path):
	'''
	return a non-existing file or directory name within a given path
	
	if a suggested name already exists, appends a number to it to make it unique
	'''
	i = 1
	assert_dir(path)
	dir_list = [x.lower() for x in os.listdir(path)]
	root, ext = os.path.splitext(name)
	while name.lower() in dir_list:
		name = root + '-' + str(i) + ext
		i += 1
	return name


def get_all_files(dir):
	'''
	returns a list of all file paths relative to `dir`
	'''
	all = []
	for root, dirs, files in os.walk(dir):
		all += map(lambda file: root + '/' + file, files)
	return all


def get_file_metadata(filename):
	'''
	returns a all available file metadata if file is an image, or None if non-image
	'''
	# return none if the file is not an image
	try:
		img = Image.open(filename)
		width, height = img.size
	except (IOError):
		return None
	
	# check for image type and jpeg file integrity
	jpeginfo = subprocess.Popen('jpeginfo -c "%s"' % filename, stdout=subprocess.PIPE, shell=True).stdout.read()
	
	# if the image is a jpeg file, get more info
	if 'not a jpeg file' not in jpeginfo.lower():
		status = re.search("\[([^\[]*)\]", jpeginfo)
		status = status.group(1) if status else 'UNKNOWN'
		if status == 'OK':
			corrupt = 0
		elif status == 'WARNING':
			corrupt = 2
		elif status == 'ERROR':
			corrupt = 3
		else:
			corrupt = 1
		
		# collect EXIF data
		try:
			exif = img._getexif() or {}
			meta = {
				ExifTags.TAGS[k]: v
				for k, v in exif.items()
				if k in ExifTags.TAGS
			}
		except (IndexError, AttributeError):
			if corrupt < 2:
				status = 'META_ERROR'
				corrupt = 3
				meta = {}
	else:
		status = 'UNKNOWN'
		corrupt = 1
		meta = {}
	
	# process and format all exif dates
	try:
		if 'DateTime' in meta:
			meta['DateTime'] = datetime.strptime(meta['DateTime'], '%Y:%m:%d %H:%M:%S')
		else:
			meta['DateTime'] = None
		
		if 'DateTimeOriginal' in meta:
			meta['DateTimeOriginal'] = datetime.strptime(meta['DateTimeOriginal'], '%Y:%m:%d %H:%M:%S')
		else:
			meta['DateTimeOriginal'] = None
		
		if 'DateTimeDigitized' in meta:
			meta['DateTimeDigitized'] = datetime.strptime(meta['DateTimeDigitized'], '%Y:%m:%d %H:%M:%S')
		else:
			meta['DateTimeDigitized'] = None
	except (TypeError, ValueError):
		meta['DateTime'] = None
		meta['DateTimeOriginal'] = None
		meta['DateTimeDigitized'] = None
	
	# compile all available image information
	info = {
		'hdr':     int(meta['CustomRendered']) if 'CustomRendered' in meta else 0,
		'width':   width,
		'height':  height,
		'status':  status,
		'corrupt': corrupt,
		'date_taken':     meta['DateTimeOriginal'],
		'date_modified':  meta['DateTime'],
		'date_digitized': meta['DateTimeDigitized'],
		'file': {
			'ctime': datetime.fromtimestamp(os.path.getctime(filename)),
			'mtime': datetime.fromtimestamp(os.path.getmtime(filename)),
			'atime': datetime.fromtimestamp(os.path.getatime(filename))
		},
		'meta': meta
	}
	
	return info


def get_file_hash(filepath, blocksize=65536):
	'''
	return a md5 hash hex string of the target file
	'''
	afile = open(filepath, 'rb')
	hasher = hashlib.md5()
	buf = afile.read(blocksize)
	while len(buf) > 0:
		hasher.update(buf)
		buf = afile.read(blocksize)
	afile.close()
	return hasher.hexdigest()


def logger(path, verbose=True, mirror_pretext=None):
	'''
	return a function which can be used to append to logs, enclosing the provided parameters.
	'''
	assert_dir(os.path.dirname(path))
	used = [path]
	
	def log(message, mirrors=None, echo=None):
		
		# allow echo to override verbose setting if specified
		if echo or (verbose and echo != False):
			print message
		
		if not mirrors:
			mirrors = []
		elif not type(mirrors) == list:
			mirrors = [mirrors]
		
		logfiles = [path] + mirrors
		for logfile in logfiles:
			with open(logfile, 'a') as res:
				if not (logfile in used):
					used.append(logfile)
					if mirror_pretext:
						res.write(mirror_pretext + "\n")
				res.write(message + "\n")
	return log


if __name__ == "__main__":
	try:
		main()
	except KeyboardInterrupt:
		print "\nOpteration Aborted\n"